<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
<style>
/* CSS for Markstat 2.0 using Pandoc 2.0 */
/* Adapted from original */

html{width:70%; margin:2rem auto;}
body{padding:14px 28px;}
body, table {font-family: Helvetica, Arial, Sans-serif; font-size: 14px;}
h1, h2, h3, h4 {font-weight: normal; color: #000}
h1 {font-size: 200%;}
h2 {font-size: 150%;}
h3 {font-size: 120%;}
h4 {font-size: 100%; font-weight:bold}
img.center {display:block; margin-left:auto; margin-right:auto}
.small{font-size:8pt;}
a {color: black;}
a:visited {color: #808080;}
a.plain {text-decoration:none;}
a.plain:hover {text-decoration:underline;}
.em {font-weight:bold;}
pre, code {font-family: "lucida console", monospace;}
pre.stata {font-size:13px; line-height:13px;}
pre {padding:8px; border:1px solid #c0c0c0; border-radius:8px; background-color:#fdfdfd;}
code {color:#000; background-color:#efefef;}
pre code { color:black; background-color:white}

/* Added for Pandoc */
figure > img, div.figure > img {display:block; margin:auto}
figcaption, p.caption {text-align:center; font-weight:bold; color:#000;}
h1.title {text-align:center; margin-bottom:0}
p.author, h2.author {font-style:italic; text-align:center;margin-top:4px;margin-bottom:0}
p.date, h3.date {text-align:center;margin-top:4px; margin-bottom:0}
p+img {text-align:center;}

/* Tables*/
table { margin:auto; border-collapse:collapse; }
table caption { margin-bottom:1ex;}
th, td { padding:4px 6px;}
thead tr:first-child th {border-top:1px solid black; padding-top:6px}
thead tr:last-child  th {padding-bottom:6px}
tbody tr:first-child td {border-top:1px solid black; padding-top:6px}
tbody tr:last-child  td {padding-bottom:6px;}
table tbody:last-child tr:last-child td {border-bottom:1px solid black;}
</style>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Dale Barnhart, Robert Brenan, Simo Goshev" />
  <title>Introduction to Missing Data and Imputation (Session 1)</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Introduction to Missing Data and Imputation (Session 1)</h1>
<p class="author">Dale Barnhart, Robert Brenan, Simo Goshev</p>
<p class="date">4 Oct 2018 , v0.01</p>
</header>
<p><em>The following is taken from Simo’s tutorial on missing data</em></p>
<h2 id="missing-data">Missing data</h2>
<h3 id="what-is-missing-data">What is missing data?</h3>
<p>Generally we want data to be complete – that is we wish that all individuals we have sampled agree to be interviewed and subsequently provide valid responses to all applicable questions in the questionnaire.</p>
<p>However, more often than not data are incomplete. For example, sampled individuals may fall out of reach (i.e. move or simply ignore us), or decline to be interviewed. If we retained this type of respondents in the sample, our dataset would have observations that are subject to <em>unit non-response</em>. That is, we would not have any response data at all for these subjects.</p>
<p>Subjects can also decline to answer certain questions or simply skip questions. This is known as <em>item non-response</em> and it manifests as a “gappy” pattern in the dataset.</p>
<p>Unit and item non-response are the patterns of missingness commonly present in data used in social science research, and missing data, as you can tell already, is simply the full or partial absence of valid values or measurements for one or more subjects for one or more variables.</p>
<h3 id="why-missing-data-may-be-a-problem">Why missing data may be a problem?</h3>
<h2 id="missing-data-mechanisms">Missing data mechanisms</h2>
<p>As we will see shortly, there are three distinct missing-data mechanisms talked about in the literature. To understand better these mechanisms and how they defer from each other, we first need to define two terms: <em>observed</em> and <em>unobserved</em> data.</p>
<p><strong>Observed data</strong> are the values or measurements that a researcher collects. In our example dataset, these would be the recorded values (except for the missing values) of the eight variables.</p>
<p><strong>Unobserved data</strong> are data that a researcher fails to measure. These data are represented by the missing values in our variables.</p>
<h3 id="missing-completely-at-random-mcar">Missing completely at random (MCAR)</h3>
<p>When we say that data are missing completely at random (MCAR), we mean that the missing-data mechanism is independent of both the observed and unobserved data. We can think of MCAR as a mechanism that introduces missigness to complete data by changing, on an entirely independent and random basis, the values of some variables to missing.</p>
<p>In theory, we would not expect incomplete records (or observations that contain missing values for some variables) to differ systematically from complete records.</p>
<p>When working with social surveys, very rarely can researchers claim/assume that missingness is MCAR. The reason is that usually there are underlying causes for subjects not to respond, causes which may or may not have been observed by the researcher (as part of the study).</p>
<h3 id="missing-at-random-mar">Missing at random (MAR)</h3>
<p>When we say that data are missing at random (MAR), we mean that the missing-data mechanism is dependent on the observed data but is independent of the unobserved data. We can think of this mechanism as one that introduces missigness to complete data by changing the values of some variables to missing based on the observed values of other variables belonging to the same record (subject).</p>
<p>In theory, we expect to see difference between complete and MAR data, specifically in the variables affected by missingness.</p>
<p>Since under MAR the mechanism of the missing data is dependent on the observed data only, we are able to both test (see Little 1988) for this missingness mechanism and address the missingness methodologically.</p>
<p>When working with social surveys, MAR is the type of mechanism that is commonly assumed. There are standard methods for handling it, some of which we will discuss shortly.</p>
<h3 id="missing-not-at-random-mnar">Missing not at random (MNAR)</h3>
<p>When we say that data are missing not at random (MNAR), we mean that the missing-data mechanism is dependent on the unobserved data. We can think of this mechanism as one that introduces missigness to complete data by changing the values of some variables to missing based on either the unobserved values of the same variable or the values of other, unobserved variables belonging to the same record.</p>
<p>With MNAR, we expect incomplete and complete cases to differ systematically. There are several classes of methods that can handle MNAR data of which sample selection models (with the Heckman selection model being the flagship model) is the most popular class in social science.</p>
<h3 id="why-is-this-distinction-important">Why is this distinction important?</h3>
<p>We conduct analyses to estimate quantities of interest and we want our estimates to be unbiased (or consistent) and efficient. Missingness can impact both of these characteristics in different ways depending on the underlying missing-data mechanism. The following table offers a summary of the effect of missingness on the characteristics of estimates (assuming again we are using complete cases only):</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Missingness</th>
<th style="text-align: center;">Bias</th>
<th style="text-align: center;">Efficiency</th>
<th style="text-align: center;">Can be corrected?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">MCAR</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Lesser</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td style="text-align: center;">MAR</td>
<td style="text-align: center;">? Yes</td>
<td style="text-align: center;">? Lesser</td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MNAR</td>
<td style="text-align: center;">? Yes</td>
<td style="text-align: center;">? Lesser</td>
<td style="text-align: center;">? Yes</td>
</tr>
</tbody>
</table>
<h2 id="strategies-for-handling-anticipated-missingness">Strategies for Handling (Anticipated) Missingness</h2>
<p>We have seen so far that missingness may impact the estimates of quantities of interest. Data collectors and applied researchers utilize a variety of strategies and methods to minimize or mitigate the impact of missingness.</p>
<h3 id="prior-to-data-collection">Prior to data collection</h3>
<p>As the old saying goes, “Design trumps model”. And it could not be more relevant to addressing missingness. To minimize missingness, the data collector has to maximize effort in designing a solid data collection plan (containing various provisions and fallbacks) and executing it with a high level of fidelity.</p>
<h4 id="oversampling">Oversampling</h4>
<p>At the stage of survey sampling design, it is almost always advisable to provision for oversampling. Oversampling means that we will sample more subjects that we think we would need. How many more subject you may ask? Well, some survey agencies sample 5% more, others sample 10% more. It all depends on the amount of missingness or non-response one might expect (and also of course on cost).</p>
<p>If in doubt, it is always recommended to ask a survey design specialist and/or someone very familiar with the population that will give rise to the sample.</p>
<h4 id="pilot-studies">Pilot studies</h4>
<p>Researchers should always run pilot studies. Pilots can help in several imporant ways:</p>
<ul>
<li><p>Validate the survey instrument (questionnaire that is)</p></li>
<li><p>Validate the rules and procedures of data collection, management and storage</p></li>
<li><p>Gain preliminary inderstanding of expected unit and item non-response</p></li>
<li><p>Test strategies for minimizing non-response (i.e. incentivisation)</p></li>
</ul>
<h4 id="rigor-during-data-collection">Rigor during data collection</h4>
<p>Once a respondent agrees to participate, we want to help them provide a complete response. This may mean working around respondent’s constraints or employing some form of incentivisation. We always want to consult with the Institutional Review Board’s (IRB) about acceptable forms of incentivising response.</p>
<h3 id="after-data-collection">After data collection</h3>
<p>Despite our best effort during the planning and collection stages, our data may still be subject to missingness. What can we do ex-post?</p>
<h4 id="weighting">Weighting</h4>
<p>Weighting, or adjusting the relative contribution of respondents’ data to estimated quantities of interest, is a popular way of correcting for unit and item non-response.</p>
<p>One of the most popular weighting techniques involves calculating probability of reponse weights for each subject in the sample and then using these weights in subsequent analyses. This technique is known as <em>inverse probability weighting</em> (IPW). In the context of a MAR dataset where subjects in the middle age-range skipped or declined questions on income, exercise and education (the process we had previously), IPW could be implemented in the following manner: we would predict the probability of a complete response for every subject as a function of age, and then use the inverse of the predicted probabilities as a probability weight in our complete-case regression of happiness on physical exercise.</p>
<hr />
<p><em>What does IPW really do for us?</em></p>
<p>Suppose the likelihood of responding of a person of a specific age is 1. This means that everyone of this age would respond to the income, exercise and education questions and therefore everyone of this age for the purpose of our analysis would be counted once. Now, suppose the likelihood of responding to three questions for a person of a different age is 0.5. This means that we would expect only half of the people of this age to respond and therefore everyone who actually responds will be given a weight of 2, or will be counted twice: once for themselves and once for a respondent of the same age who did not respond. With a likelihood of 0.1, everyone of the same age who responded will represent themselves and 9 other non-responders of the same age.</p>
<hr />
<p><em>Two-phase estimation for missing data</em></p>
<p>This is a method that assumes the following process governing missingness:</p>
<p>Phase 1: Original sample selected and variables without missing values are measured<br />
Phase 2: A subset of respondents is selected and the remaining variable are observed</p>
<p>Obvious limitations of this method? It is only useful when we can divide the observations into complete and incomplete</p>
<h4 id="imputation">Imputation</h4>
<p>Imputation methods are an alternative. Imputation generally refers to the process of filling in the “gaps” or missingness in our dataset with valid values in a principled manner. Imputation methods generally fall into two categories: methods for <em>single imputation</em> and methods for <em>multiple imputation</em>. <br> <br></p>
<p><em>Single imputation</em></p>
<p>Methods that fall under the umbrella of <em>single imputation</em> include hot- and cold-deck imputation, mean substitution and regression.</p>
<p><em>Hot-deck imputation</em></p>
<p>The method involves replacing missing values with values from a random <em>similar</em> observation in the same dataset.</p>
<p><em>Cold-desk imputation</em></p>
<p>The method involves replacing missing values with values from a random <em>similar</em> observation from a different dataset.</p>
<p><em>Mean substitution</em></p>
<p>The method involves replacing missing values of a variable with the <em>mean</em> value of the variable computed over non-missing observations.</p>
<p><em>Regression</em></p>
<p>The method involves estimating a regression equation from all complete cases and then replacing the missing values with the respective predicted values from the regression. <br></p>
<p>There are many other single imputation techniques but ultimately all of them are subject to one common limitation. Could you name it? <br> <br></p>
<p><em>Multiple imputation (MI)</em></p>
<p>Multiple imputation, a simulation-based technique proposed by Donald Rubin, overcomes the problems of variability that single imputation methods fail to address. (Yes, single imputation methods do not account for the uncertainty in the imputed values; that is their common limitation.) In a series of articles in the 1970’s and 1980’s, culminating with his seminal book “Multiple Imputation for Nonresponse in Surveys” published in 1987, Rubin developed the theoretical basis of MI and proposed the following general algorithm for its implementation:</p>
<ol type="1">
<li>Impute the missing values <span class="math inline">\(M\)</span> times, thus generating <span class="math inline">\(M\)</span> complete datasets</li>
<li>Estimate the quantities of interest from every <span class="math inline">\(m\)</span> dataset in <span class="math inline">\(M\)</span></li>
<li>Combine the estimates from every dataset in <span class="math inline">\(M\)</span> into a final set of estimates that can be used for inference.</li>
</ol>
<p>The following formulas for aggregation used in Step 3 are known as the <em>Rubin’s rules</em>:</p>
<p><span class="math display">\[
    \hat{\beta} = \frac{1}{m}\sum_{m=1}^{M}\hat{\beta}_{m}
\]</span> <span class="math display">\[
    V_{\beta} = W + (1 + \frac{1}{m})B
\]</span></p>
<p>where <span class="math display">\[
    W=\frac{1}{m}\sum_{m=1}^{M}s_{m}^{2}
\]</span> <span class="math display">\[
    B=\frac{1}{m-1}\sum_{m=1}^{M}(\hat{\beta}_{m} - \hat{\beta})^{2}
\]</span></p>
<p>Nowadays, multiple imputation is the recommended technique for handling missing data. <br> <br></p>
<p><em>Full-likelihood methods (FLM)</em></p>
<p>FLM are based on the joint distribution of the variables affected by missingness together with the outcome of the regression model we wish to estimate. We specify a likelihood function which we then estimate to retrieve the most likely regression paratemers. A main limitation of this method is that all variables need to be continuous and the regression model has to be linear. <br> <br></p>
<p><em>Doubly robust methods (DRM)</em></p>
<p>While with IPW weighting methods we model the probability of complete cases and mulitple imputation models the distribution of missing variables, DRM combine the two approaches. Generally, DRM use two models: one predicts the missing values and the other predicts the missing probabilities (which are used as weights). There are both parametric and semi-parametric implemetations of DRM but they have remained somewhat on the sidelines in social science research.</p>
<p><br> <br></p>
<h2 id="multiple-imputation">Multiple Imputation</h2>
<p>Multiple imputation methods fall under two broad categories: <em>univariate</em> MI methods and <em>multivariate</em> MI methods. We use univariate methods for multiple imputation if missingness is MAR and we wish to impute the missing values of a single variable. In comparison, multivariate mulitple imputation (MMI) methods are helpful if (missingness is MAR and) we wish to impute multiple variables with missing values simultaneously and in relation to one other.</p>
<p>This ability to allow for relationships among the variables (missing or non-missing) in a dataset is what makes the MMI methods so popular in social science research. We will focus on three distinct flavors of MMI in order of specification flexibility they provide: imputation using multivariate normal regression, imputation in monotone data, and chained imputation.</p>
<h3 id="imputation-using-multivariate-normal-regression">Imputation using multivariate normal regression</h3>
<p>This method of imputation can be used when imputing one or more continuous variables. It uses multivariate normal regression to model the mean function and Markov Chain Monte Carlo to impute the missing values.</p>
<hr />
<p><em>Oh wait, what is a Markov chain?</em></p>
<p>A Markov chain is a mathematical model of a stochastic system. It is defined by a set of states and a set of transition probabilities for traversing among these states. Intuitively, we can think of Markov chains as random walks on graphs. <a href="http://setosa.io/ev/markov-chains/"><em>This</em></a> website has several interactive examples of Markov chains that can help us understand them better.</p>
<p><em>And what is a Markov Chain Monte Carlo (MCMC)?</em></p>
<p>MCMC is a class of algorithms that allow us to sample from complex probability distributions. The Monte Carlo part of MCMC refers to the fact that we are simulating a distribution and the Markov Chain part refers to the fact that we are using a Markov chain to do the sampling.</p>
<p><em>And how does MCMC impute the missing values?</em></p>
<p>Under specific conditions, a Markov chain will have a <em>stationary distribution</em>. This means that for a sufficiently long random walk, the set of transition probabilities will converge to some fixed quantities and will not depend on the starting state of the walk.</p>
<p>Now, if we set the stationary distribution of the Markov chain to the distribution that we wish to sample from (i.e. the <em>target distribution</em>), for a sufficiently long random walk, the Markov chain will reproduce empirically this distribution and will help us sample from it. In imputation problems (based on regression), we normally pick a target distribution and a mean function and let the developers of statistical software choose the specific MCMC algorithm that would be most efficient for sampling from this distribution.</p>
<hr />
<p>The imputation algorithm has two steps: an <em>imputation</em> step and a <em>posterior</em> step. In the imputation step, the missing values are replaced by draws from our target distribution – a multivariate normal distribution, conditional on the observed data and current values of the model parameters. In the posterior step, new values of the model parameters and variance are drawn from their respective distributions, conditional on the observed data and the imputed values from the previous imputation step. This procedure is repeated until a pre-specified number of iterations is reached.</p>
<p>An obvious disadvantage of this method is that it only works for imputing continuous variables (that need to follow a normal distribution). This is a pretty significant limitation considering the variety of variable types that are present in social science data.</p>
<h3 id="imputation-in-monotone-data">Imputation in monotone data</h3>
<p>To understand this method, first we need to define the term “monotone missing pattern”. Data exhibit a monotone missing pattern if missingness in variable <span class="math inline">\(Y_{j}\)</span> for subject <em>i</em> means that variables <span class="math inline">\(Y_{k}\)</span>, where <span class="math inline">\(k &gt; j\)</span> for subject <em>i</em> are also missing.</p>
<p>The presence of a monotone missing pattern in data simplifies the imputation task by reducing it to a sequence of independent univariate (possibly conditional) imputation tasks.</p>
<p>The imputation algorithm has the following general logic:</p>
<p><span class="math display">\[\begin{equation}
\begin{array}{clc}

X_{1}^{*} \leftarrow Z \\
X_{2}^{*} \leftarrow X_{1}^{*}, Z \\
X_{3}^{*} \leftarrow X_{1}^{*}, X_{2}^{*}, Z

\end{array}
\end{equation}\]</span></p>
<p>The advantages of this method are that not only can we simplify the imputation task but we can also specify univariate models that correspond to the types of variables we are imputing. This is a rather big improvement over the method of multivariate normal regression. The disadvantage is that it is quite uncommon for data to have a monotone missing pattern.</p>
<h3 id="multiple-imputation-using-chained-equations">Multiple imputation using chained equations</h3>
<p>Multiple imputation using chained equations (MICE) is the most popular method for imputation in social science research. Its popularity is based primarily on its ability to impute multiple variables of different types simultaneously and conditional on one another.</p>
<p>One iteration of the imputation algorithm has the following general logic:</p>
<p><span class="math display">\[\begin{equation}
\begin{array}{clc}

X_{1} \leftarrow \boldsymbol{X_{-1}}, Z \\
X_{2} \leftarrow \boldsymbol{X_{-2}}, Z \\
X_{3} \leftarrow \boldsymbol{X_{-3}}, Z

\end{array}
\end{equation}\]</span></p>
<p>In essence, MICE is based on a series of univariate imputation models, each of which is selected to correspond to the type of variable ( e.g. continuous, categorical, proportion, etc.) that is being imputed. It uses chained equations, meaning that an outcome in one imputation equation by default (and this can be customized) is a predictor in all other equations. MICE is similar in logic to MCMC in that it builds a chain, iterates until the chain attains its stationary distribution and samples from it to replace the missing observations.</p>
<hr />
<p><em>Some ‘ground rules’ of imputation</em></p>
<p>Multiple imputation is an extremely useful technique that can help us tackle missing data problems in a principled and statistically sound manner. However, practitioners should remain vigilent and not fall into some common pitfalls associated with the procedure.</p>
<p>To avoid trouble:</p>
<ul>
<li>We need to understand our data very well. We need to know whether all conditions for imputation are met, variables it makes sense to impute and variables that we should not impute for certain groups (e.g. wages for one-year-olds).</li>
<li>We should not rely on statistical software to know how to handle our data properly. Indiscriminately throwing variables into an imputation routine and expecting the software to know their meaning and make decisions for us is a recipe for disaster. Likewise, cherry picking variables to include in imputation models is nothing short of bad research practice.</li>
<li>We must pay attention to attrition and selection. Imputation algorithms do not know anything about this aspect of our missing data problem and would assume it away. Borrowing information from non-comparable subjects could severely affect the quality of our imputation and inference.</li>
<li>The amount of missingness and sample size matter for the performance of imputation routines! The rule of thumb is that missingness of about 10% is manageable, and missingness of 25% is high and likely problematic, especially in samples of smaller size.</li>
</ul>
<hr />
<h2 id="imputation-in-panel-data">Imputation in panel data</h2>
<p>Imputing panel data is similar to imputing cross-sectional data. Before imputation however, we would reshape the data from long to wide form. This is really important as imputation routines do not normally know the ways in which observations are be related and if the data are imputed while still in long form, in essence, the software would be making the assumption that observations of the same individual for different time periods are uncorrelated; and that would be a silly thing to assume!</p>
<h2 id="references">References</h2>
<p>Mack C, Su Z, Westreich D. Rockville (MD): Agency for Healthcare Research and Quality (US); 2018 Feb.</p>
<p>Little, R. J. A. 1988. A test of missing completely at random for multivariate data with missing values. Journal of the American Statistical Association 83: 1198–1202.</p>
<p>Cheng Li, Little’s test of missing completely at random The Stata Journal (2013) 13, Number 4, pp. 795–809</p>
<p>Rubin, Multiple Imputation After 18+ Years,Journal of the American Statistical Association, Vol. 91, No. 434 (Jun., 1996), pp.473-489</p>
<p>Lumley, T., 2010, Complex Surveys. A guide to analysis in R.</p>
<p>van Buuren, S., Groothuis-Oudshoorn, K., 2011, mice: Multivariate Imputation by Chained Equations in R, Journal of Statistical Software</p>
<p>Stata, 2017, Stata Multiple-Imputation Reference Manual, Stata Crop LLC, College Station, Texas</p>
</body>
</html>
